{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "annts.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2JNF/O5V9FYGk2oMS/QLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NurFaizin/ann-backpropagation-regression/blob/main/annts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhrPkiyPrOg1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGUVV2ZQtlm-"
      },
      "source": [
        "def relu(z):\n",
        "    a = np.maximum(0,z)\n",
        "    return a"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Eeoy9KyvKec"
      },
      "source": [
        "def initialize_params(layer_sizes):\n",
        "    params = {}\n",
        "    for i in range(1, len(layer_sizes)):\n",
        "        params['W' + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1])*0.01\n",
        "        params['B' + str(i)] = np.random.randn(layer_sizes[i],1)*0.01\n",
        "    print(params)\n",
        "    return params"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbtmcBqRvOO1"
      },
      "source": [
        "def forward_propagation(X_train, params):\n",
        "    layers = len(params)//2\n",
        "    values = {}\n",
        "    for i in range(1, layers+1):\n",
        "        if i==1:\n",
        "            values['Z' + str(i)] = np.dot(params['W' + str(i)], X_train) + params['B' + str(i)]\n",
        "            values['A' + str(i)] = relu(values['Z' + str(i)])\n",
        "        else:\n",
        "            values['Z' + str(i)] = np.dot(params['W' + str(i)], values['A' + str(i-1)]) + params['B' + str(i)]\n",
        "            if i==layers:\n",
        "                values['A' + str(i)] = values['Z' + str(i)]\n",
        "            else:\n",
        "                values['A' + str(i)] = relu(values['Z' + str(i)])\n",
        "    return values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cVaaMMvvRVS"
      },
      "source": [
        "def compute_cost(values, Y_train):\n",
        "    layers = len(values)//2\n",
        "    Y_pred = values['A' + str(layers)]\n",
        "    cost = 1/(2*len(Y_train)) * np.sum(np.square(Y_pred - Y_train))\n",
        "    return cost"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvtk9IlavT7Z"
      },
      "source": [
        "def backward_propagation(params, values, X_train, Y_train):\n",
        "    layers = len(params)//2\n",
        "    m = len(Y_train)\n",
        "    grads = {}\n",
        "    for i in range(layers,0,-1):\n",
        "        if i==layers:\n",
        "            dA = 1/m * (values['A' + str(i)] - Y_train)\n",
        "            dZ = dA\n",
        "        else:\n",
        "            dA = np.dot(params['W' + str(i+1)].T, dZ)\n",
        "            dZ = np.multiply(dA, np.where(values['A' + str(i)]>=0, 1, 0))\n",
        "        if i==1:\n",
        "            grads['W' + str(i)] = 1/m * np.dot(dZ, X_train.T)\n",
        "            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
        "        else:\n",
        "            grads['W' + str(i)] = 1/m * np.dot(dZ,values['A' + str(i-1)].T)\n",
        "            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
        "    return grads\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaOIr1eEvXH5"
      },
      "source": [
        "def update_params(params, grads, learning_rate):\n",
        "    layers = len(params)//2\n",
        "    params_updated = {}\n",
        "    for i in range(1,layers+1):\n",
        "        params_updated['W' + str(i)] = params['W' + str(i)] - learning_rate * grads['W' + str(i)]\n",
        "        params_updated['B' + str(i)] = params['B' + str(i)] - learning_rate * grads['B' + str(i)]\n",
        "    return params_updated"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iUixxGxvaJh"
      },
      "source": [
        "def model(X_train, Y_train, layer_sizes, num_iters, learning_rate):\n",
        "    params = initialize_params(layer_sizes)\n",
        "    for i in range(num_iters):\n",
        "        values = forward_propagation(X_train.T, params)\n",
        "        cost = compute_cost(values, Y_train.T)\n",
        "        grads = backward_propagation(params, values,X_train.T, Y_train.T)\n",
        "        params = update_params(params, grads, learning_rate)\n",
        "        print('Cost at iteration ' + str(i+1) + ' = ' + str(cost) + '\\n')\n",
        "    return params"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUVY845Jve12"
      },
      "source": [
        "def compute_accuracy(X_train, X_test, Y_train, Y_test, params):\n",
        "    values_train = forward_propagation(X_train.T, params)\n",
        "    values_test = forward_propagation(X_test.T, params)\n",
        "    train_acc = mean_squared_error(Y_train, values_train['A' + str(len(layer_sizes)-1)].T)\n",
        "    test_acc = mean_squared_error(Y_test, values_test['A' + str(len(layer_sizes)-1)].T)\n",
        "    return train_acc, test_acc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSk4gxK5vhwV"
      },
      "source": [
        "def predict(X, params):\n",
        "    values = forward_propagation(X.T, params)\n",
        "    predictions = values['A' + str(len(values)//2)].T\n",
        "    return predictions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOwGnvSvlwY"
      },
      "source": [
        "data = load_boston()                                                              #load dataset\n",
        "X,Y = data[\"data\"], data[\"target\"]                                                #separate data into input and output features\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2)           #split data into train and test sets in 80-20 ratio"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv52bxIPwCNG"
      },
      "source": [
        "layer_sizes = [13, 5, 5, 1]                                                       #set layer sizes, do not change the size of the first and last layer \n",
        "num_iters = 10                                                                  #set number of iterations over the training set(also known as epochs in batch gradient descent context)\n",
        "learning_rate = 0.05                                                              #set learning rate for gradient descent"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZgFZIXHwKMs",
        "outputId": "383ef78e-3b27-4c2a-96eb-b19de922d104"
      },
      "source": [
        "params = model(X_train, Y_train, layer_sizes, num_iters, learning_rate)           #train the model\n",
        "train_acc, test_acc = compute_accuracy(X_train, X_test, Y_train, Y_test, params)  #get training and test accuracy"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'W1': array([[-0.01987646, -0.01648039, -0.00812933, -0.00314752, -0.0014914 ,\n",
            "        -0.00018889, -0.00068595,  0.00027011,  0.01337197,  0.00985507,\n",
            "        -0.01054339, -0.0106918 ,  0.00382479],\n",
            "       [ 0.00700548, -0.02824674,  0.01158062, -0.00304319,  0.00338397,\n",
            "         0.00694075,  0.00172341, -0.0041179 ,  0.008439  ,  0.00627464,\n",
            "        -0.00475992,  0.00792243,  0.00394957],\n",
            "       [ 0.0030709 , -0.01831788,  0.00779384, -0.00204208, -0.00356374,\n",
            "         0.01918188,  0.00075539,  0.00820069, -0.00444025, -0.0033358 ,\n",
            "         0.00591393, -0.00123545, -0.01022899],\n",
            "       [ 0.0007677 ,  0.00219899, -0.011167  , -0.00411237, -0.00895719,\n",
            "        -0.00110955, -0.00835805, -0.00874897,  0.00228144, -0.01106464,\n",
            "         0.00051064, -0.00375546, -0.02357263],\n",
            "       [-0.01358749,  0.00762688, -0.01360596, -0.01181987, -0.00725035,\n",
            "        -0.0038445 , -0.00129477,  0.00378545,  0.00707509, -0.00370555,\n",
            "         0.00253246, -0.00338061, -0.00152293]]), 'B1': array([[-0.00229329],\n",
            "       [ 0.00668804],\n",
            "       [-0.01756808],\n",
            "       [-0.00164891],\n",
            "       [ 0.00482021]]), 'W2': array([[ 0.0120067 ,  0.00165389, -0.00528804,  0.01272779,  0.00668965],\n",
            "       [-0.00162027,  0.00810547,  0.01526757, -0.00929155,  0.01107811],\n",
            "       [-0.00472189, -0.00522247,  0.00126943, -0.00457502,  0.00334523],\n",
            "       [-0.00035039,  0.00642481, -0.00258984,  0.0019948 ,  0.00547364],\n",
            "       [ 0.0114889 , -0.00400543,  0.00777605,  0.00430822, -0.00451342]]), 'B2': array([[-0.00762126],\n",
            "       [-0.01415872],\n",
            "       [-0.01221136],\n",
            "       [-0.00717632],\n",
            "       [ 0.02002226]]), 'W3': array([[ 0.00765403, -0.00848691, -0.00622946,  0.00501215, -0.00156796]]), 'B3': array([[-0.00802272]])}\n",
            "Cost at iteration 1 = 304.453318870612\n",
            "\n",
            "Cost at iteration 2 = 304.3882292321949\n",
            "\n",
            "Cost at iteration 3 = 304.32314155313594\n",
            "\n",
            "Cost at iteration 4 = 304.2580584337916\n",
            "\n",
            "Cost at iteration 5 = 304.1929797152082\n",
            "\n",
            "Cost at iteration 6 = 304.1279071905335\n",
            "\n",
            "Cost at iteration 7 = 304.0628378347783\n",
            "\n",
            "Cost at iteration 8 = 303.99776625388654\n",
            "\n",
            "Cost at iteration 9 = 303.93269499145475\n",
            "\n",
            "Cost at iteration 10 = 303.86762556724733\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keVmKa3-wTXz",
        "outputId": "187cb451-cd52-48ef-f12a-21b89f2e2038"
      },
      "source": [
        "print('Root Mean Squared Error on Training Data = ' + str(train_acc))\n",
        "print('Root Mean Squared Error on Test Data = ' + str(test_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error on Training Data = 76.9588299913496\n",
            "Root Mean Squared Error on Test Data = 72.41929366835697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_sQHNvyD-s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}